{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer #어간추출\n",
    "from gensim import corpora, models\n",
    "import matplotlib.pyplot as plt #시각화를 위한\n",
    "import gensim\n",
    "import pandas as pd\n",
    "#import string\n",
    "#import re\n",
    "#from konlpy.tag import Twitter #설치 에러\n",
    "#from wordcloud import WordCloud #설치 에러\n",
    "#from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv(\"./data/tt.csv\", encoding=\"ISO-8859-1\")\n",
    "spam = pd.read_csv(\"./data/spam.csv\", encoding=\"ISO-8859-1\")\n",
    "spam_test = pd.read_csv(\"./data/spam_test.csv\", encoding=\"ISO-8859-1\")\n",
    "ham = pd.read_csv(\"./data/ham.csv\", encoding=\"ISO-8859-1\")\n",
    "ham_test = pd.read_csv(\"./data/ham_test.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tt['Unnamed: 2']\n",
    "del tt['Unnamed: 3']\n",
    "del tt['Unnamed: 4']\n",
    "tt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ham은 0으로, spam은 1로 변환\n",
    "tt['v1']=tt['v1'].replace(['ham','spam'],[0,1])\n",
    "tt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   int64 \n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 65.4+ KB\n"
     ]
    }
   ],
   "source": [
    "tt.info()\n",
    "#v1은 0과 1로 된 int형 \n",
    "#v2는 object 문자열 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#null 값이 있는지 확인  -->결과 Null 값이 존재하지 않음\n",
    "tt.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5169\n"
     ]
    }
   ],
   "source": [
    "#중복데이터가 있는지 확인  -->5,572-5,169 = 403개의 중복 샘플 존재\n",
    "tt['v2'].nunique(), tt['v1'].nunique()\n",
    "#중복 제거\n",
    "tt.drop_duplicates(subset=['v2'], inplace=True)\n",
    "print(len(tt)) #데이터 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18d06cb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data에 존재하는 spam과 ham의 데이터 수를 확인\n",
    "tt['v1'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SMS메세지 중 대부분이 정상 메일이고 소수가 스팸메일이라는 것을 알 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1\n",
      "0    4516\n",
      "1     653\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tt.groupby('v1').size()) #v1에 있는 ham(0)개수와 spam(1)개수를 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nx_tt = tt['v2'] #SMS 메세지 (input data)\\ny_tt = tt['v1'] #f레이블: ham(0)이냐 spam(1)이냐 \\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "x_tt = tt['v2'] #SMS 메세지 (input data)\n",
    "y_tt = tt['v1'] #f레이블: ham(0)이냐 spam(1)이냐 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tt) #dataFrame으로 분류 됨!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_list=list(spam['v2'])\n",
    "ham_list=list(ham['v2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam_list 안의 문서를 읽어서 전처리 후 다시 저장\n",
    "tokenizer = RegexpTokenizer(r'\\w+') # 문장을 단어로 분리하는 모듈\n",
    "#pattern='[^\\w\\s]' #특수문자제거\n",
    "#repl='' #특수문자제거\n",
    "stop = get_stop_words('en')         # 불용어 리스트\n",
    "stemmer = PorterStemmer()           # 어간 추출기 ex)'나는 학교에 간다' -> '나 학교 가' \n",
    "spam1 = []                          # 전처리 후 문서 저장하는 리스트\n",
    "for d in spam_list:\n",
    "    if(d) :\n",
    "        raw = d.lower()\n",
    " #       raw = re.sub(pattern=pattern, repl=repl, string=raw)\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        stopped_tokens = [i for i in tokens if not i in stop]\n",
    "        stemmed_tokens = [stemmer.stem(i) for i in stopped_tokens]\n",
    "        spam1.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham_list 안의 문서를 읽어서 전처리 후 다시 저장\n",
    "tokenizer = RegexpTokenizer(r'\\w+') # 문장을 단어로 분리하는 모듈\n",
    "stop = get_stop_words('en')         # 불용어 리스트\n",
    "stemmer = PorterStemmer()           # 어간 추출기 ex)'나는 학교에 간다' -> '나 학교 가' \n",
    "ham1 = []                          # 전처리 후 문서 저장하는 리스트\n",
    "for d in ham_list:\n",
    "    if(d) :\n",
    "        raw = d.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        stopped_tokens = [i for i in tokens if not i in stop]\n",
    "        stemmed_tokens = [stemmer.stem(i) for i in stopped_tokens]\n",
    "        ham1.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LDA 모델을 적용하기 위해 document-term matrix 형태를 만들어줌\n",
    "# 전체 문서가 포함하고 있는 모든 단어로 이루어진 사전\n",
    "spam1_dictionary = corpora.Dictionary(spam1) \n",
    "spam1_dictionary\n",
    "# spam1 문서를 이용하여 doc-term matrix를 만들어줌\n",
    "spam1_corpus = [spam1_dictionary.doc2bow(text) for text in spam1]\n",
    "# 단어 빈도수가 아닌 tfidf 가중치를 적용한 모델\n",
    "spam1_tfidf = models.TfidfModel(spam1_corpus, id2word = spam1_dictionary)\n",
    "# tfidf 모델로 corpus를 적용한 결과\n",
    "spam1_corpus_tfidf = spam1_tfidf[spam1_corpus]\n",
    "# 위의 결과를 다시 LDA를 적용하기 위한 list 형태로 변형\n",
    "spam1_corpus_tfidf_list = [doc for doc in spam1_corpus_tfidf]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.006*\"free\" + 0.004*\"call\" + 0.004*\"cash\" + 0.004*\"text\" + 0.004*\"ur\" + 0.003*\"å\" + 0.003*\"txt\" + 0.003*\"servic\" + 0.003*\"4\" + 0.003*\"500\" + 0.003*\"mobil\" + 0.003*\"u\" + 0.003*\"tone\" + 0.003*\"pleas\" + 0.003*\"rington\" + 0.003*\"now\" + 0.003*\"latest\" + 0.003*\"2\" + 0.003*\"messag\" + 0.003*\"phone\"'), (1, '0.007*\"claim\" + 0.006*\"prize\" + 0.006*\"å\" + 0.005*\"won\" + 0.005*\"call\" + 0.004*\"u\" + 0.004*\"2\" + 0.004*\"award\" + 0.004*\"now\" + 0.004*\"tri\" + 0.003*\"nokia\" + 0.003*\"contact\" + 0.003*\"mobil\" + 0.003*\"urgent\" + 0.003*\"guarante\" + 0.003*\"receiv\" + 0.003*\"show\" + 0.003*\"number\" + 0.003*\"2000\" + 0.003*\"min\"'), (2, '0.004*\"stop\" + 0.003*\"day\" + 0.003*\"repli\" + 0.003*\"txt\" + 0.003*\"2\" + 0.003*\"import\" + 0.002*\"com\" + 0.002*\"www\" + 0.002*\"1\" + 0.002*\"dog\" + 0.002*\"get\" + 0.002*\"camera\" + 0.002*\"club\" + 0.002*\"messag\" + 0.002*\"text\" + 0.002*\"inform\" + 0.002*\"s\" + 0.002*\"http\" + 0.002*\"flag\" + 0.002*\"servic\"')]\n"
     ]
    }
   ],
   "source": [
    "#LDA 모델 학습\n",
    "sp_ldamodel = gensim.models.ldamodel.LdaModel(spam1_corpus_tfidf_list, num_topics=3, id2word = spam1_dictionary, passes=50)\n",
    "print(sp_ldamodel.print_topics(num_topics=20, num_words=20)) #학습결과 상위 단어 20개까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LDA 모델을 적용하기 위해 document-term matrix 형태를 만들어줌\n",
    "# 전체 문서가 포함하고 있는 모든 단어로 이루어진 사전\n",
    "ham1_dictionary = corpora.Dictionary(ham1) \n",
    "ham1_dictionary\n",
    "# ham1 문서를 이용하여 doc-term matrix를 만들어줌\n",
    "ham1_corpus = [ham1_dictionary.doc2bow(text) for text in ham1]\n",
    "# 단어 빈도수가 아닌 tfidf 가중치를 적용한 모델\n",
    "ham1_tfidf = models.TfidfModel(ham1_corpus, id2word = ham1_dictionary)\n",
    "# tfidf 모델로 corpus를 적용한 결과\n",
    "ham1_corpus_tfidf = ham1_tfidf[ham1_corpus]\n",
    "# 위의 결과를 다시 LDA를 적용하기 위한 list 형태로 변형\n",
    "ham1_corpus_tfidf_list = [doc for doc in ham1_corpus_tfidf]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.012*\"gt\" + 0.011*\"lt\" + 0.007*\"pl\" + 0.005*\"send\" + 0.005*\"u\" + 0.004*\"new\" + 0.004*\"year\" + 0.004*\"s\" + 0.003*\"need\" + 0.003*\"right\" + 0.003*\"min\" + 0.003*\"messag\" + 0.003*\"bu\" + 0.003*\"k\" + 0.003*\"done\" + 0.003*\"phone\" + 0.002*\"get\" + 0.002*\"pick\" + 0.002*\"way\" + 0.002*\"ya\"'), (1, '0.012*\"call\" + 0.010*\"ll\" + 0.010*\"ok\" + 0.008*\"later\" + 0.007*\"sorri\" + 0.007*\"can\" + 0.006*\"know\" + 0.005*\"s\" + 0.005*\"meet\" + 0.005*\"t\" + 0.005*\"m\" + 0.005*\"u\" + 0.005*\"da\" + 0.005*\"see\" + 0.004*\"get\" + 0.004*\"dont\" + 0.004*\"dear\" + 0.004*\"text\" + 0.004*\"ye\" + 0.004*\"now\"'), (2, '0.010*\"u\" + 0.008*\"go\" + 0.007*\"come\" + 0.007*\"home\" + 0.007*\"2\" + 0.006*\"lor\" + 0.006*\"m\" + 0.005*\"will\" + 0.005*\"4\" + 0.005*\"wat\" + 0.005*\"now\" + 0.004*\"time\" + 0.004*\"s\" + 0.004*\"get\" + 0.004*\"just\" + 0.004*\"alreadi\" + 0.004*\"can\" + 0.004*\"ok\" + 0.003*\"want\" + 0.003*\"thank\"')]\n"
     ]
    }
   ],
   "source": [
    "#LDA 모델 학습\n",
    "h_ldamodel = gensim.models.ldamodel.LdaModel(ham1_corpus_tfidf_list, num_topics=3, id2word = ham1_dictionary, passes=50)\n",
    "print(h_ldamodel.print_topics(num_topics=20, num_words=20)) #학습결과 상위 단어 20개까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('stop', 0.003958376), ('day', 0.003102089), ('repli', 0.0028713972), ('txt', 0.002820651), ('2', 0.002653397), ('import', 0.0026464593), ('com', 0.0022706268), ('www', 0.0022399838), ('1', 0.0022154383), ('dog', 0.0022133398), ('get', 0.0021517372), ('camera', 0.002057588), ('club', 0.0020502508), ('messag', 0.001981176), ('text', 0.001954823), ('inform', 0.0019366633), ('s', 0.0019290594), ('http', 0.0018817139), ('flag', 0.001862433), ('servic', 0.0018459309), ('msg', 0.0018256844), ('announc', 0.0018235178), ('end', 0.0017747986), ('now', 0.0017652067), ('u', 0.0017279586), ('f', 0.0017010131), ('win', 0.001697262), ('mobil', 0.001695213), ('50', 0.0016943801), ('3', 0.001670775)]\n"
     ]
    }
   ],
   "source": [
    "#토픽별 결과\n",
    "sp_result=sp_ldamodel.show_topic(2,30)\n",
    "print(sp_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('u', 0.009996082), ('go', 0.008210974), ('come', 0.007281132), ('home', 0.0066782697), ('2', 0.006516254), ('lor', 0.0061527328), ('m', 0.0058141514), ('will', 0.005471852), ('4', 0.005206049), ('wat', 0.0047958707), ('now', 0.004560252), ('time', 0.004299028), ('s', 0.003941986), ('get', 0.00367792), ('just', 0.0036657273), ('alreadi', 0.0035707734), ('can', 0.0035337664), ('ok', 0.0035144812), ('want', 0.0034309279), ('thank', 0.0034283698), ('got', 0.003334227), ('love', 0.0032634998), ('n', 0.0032174995), ('day', 0.003161417), ('k', 0.0031012066), ('im', 0.003022131), ('week', 0.0030217285), ('good', 0.0029835026), ('hope', 0.0029548667), ('today', 0.0029316451)]\n"
     ]
    }
   ],
   "source": [
    "#토픽별 결과\n",
    "h_result=h_ldamodel.show_topic(2,30)\n",
    "print(h_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-22-7d4cbafa0c7e>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-7d4cbafa0c7e>\"\u001b[1;36m, line \u001b[1;32m54\u001b[0m\n\u001b[1;33m    print('??')\u001b[0m\n\u001b[1;37m               \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def sp_h (x):\n",
    "    #spam_list 안의 문서를 읽어서 전처리 후 다시 저장\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') # 문장을 단어로 분리하는 모듈\n",
    "    #pattern='[^\\w\\s]' #특수문자제거\n",
    "    #repl='' #특수문자제거\n",
    "    stop = get_stop_words('en')         # 불용어 리스트\n",
    "    stemmer = PorterStemmer()           # 어간 추출기 ex)'나는 학교에 간다' -> '나 학교 가' \n",
    "    x1 = []                          # 전처리 후 문서 저장하는 리스트\n",
    "    for d in x:\n",
    "        if(d) :\n",
    "            raw = d.lower()\n",
    "             #raw = re.sub(pattern=pattern, repl=repl, string=raw)\n",
    "            tokens = tokenizer.tokenize(raw)\n",
    "            stopped_tokens = [i for i in tokens if not i in stop]\n",
    "            stemmed_tokens = [stemmer.stem(i) for i in stopped_tokens]\n",
    "            x1.append(stemmed_tokens)\n",
    "    \n",
    "    ### LDA 모델을 적용하기 위해 document-term matrix 형태를 만들어줌\n",
    "    # 전체 문서가 포함하고 있는 모든 단어로 이루어진 사전\n",
    "    x_dictionary = corpora.Dictionary(x1) \n",
    "    x_dictionary\n",
    "    # ham1 문서를 이용하여 doc-term matrix를 만들어줌\n",
    "    x_corpus = [x_dictionary.doc2bow(text) for text in x1]\n",
    "    # 단어 빈도수가 아닌 tfidf 가중치를 적용한 모델\n",
    "    x_tfidf = models.TfidfModel(x_corpus, id2word = x_dictionary)\n",
    "    # tfidf 모델로 corpus를 적용한 결과\n",
    "    x_corpus_tfidf = x_tfidf[x_corpus]\n",
    "    # 위의 결과를 다시 LDA를 적용하기 위한 list 형태로 변형\n",
    "    x_corpus_tfidf_list = [doc for doc in x_corpus_tfidf] \n",
    "    #LDA 모델 학습\n",
    "    x_ldamodel = gensim.models.ldamodel.LdaModel(x_corpus_tfidf_list, num_topics=3, id2word = x_dictionary, passes=50)\n",
    "    #결과\n",
    "    x_result=x_ldamodel.show_topic(2,30)\n",
    "    \n",
    "    temp1=0\n",
    "    temp2=0\n",
    "    for x1, y1 in x_result:\n",
    "        for sp_x, sp_y in sp_result:\n",
    "            num=0\n",
    "            if(x1==sp_x):\n",
    "                num=1\n",
    "                temp1=temp1+sp_y\n",
    "        for h_x, h_y in h_result:\n",
    "            num=0\n",
    "            if(x1==h_x):\n",
    "                temp2=temp2+h_y\n",
    "    \n",
    "    if(temp1>temp2):\n",
    "        print('spam')\n",
    "    if(temp1<temp2):\n",
    "        print('ham')\n",
    "    if(temp1==temp2):\n",
    "        print('??')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "spam_test1=spam_test.head(8)\n",
    "x=list(spam_test1['v2'])\n",
    "sp_h(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stop</td>\n",
       "      <td>0.003958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day</td>\n",
       "      <td>0.003102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>repli</td>\n",
       "      <td>0.002871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txt</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>import</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>com</td>\n",
       "      <td>0.002271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www</td>\n",
       "      <td>0.002240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.002213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>get</td>\n",
       "      <td>0.002152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>camera</td>\n",
       "      <td>0.002058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>club</td>\n",
       "      <td>0.002050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>messag</td>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text</td>\n",
       "      <td>0.001955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>inform</td>\n",
       "      <td>0.001937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>http</td>\n",
       "      <td>0.001882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>flag</td>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>servic</td>\n",
       "      <td>0.001846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1\n",
       "0     stop  0.003958\n",
       "1      day  0.003102\n",
       "2    repli  0.002871\n",
       "3      txt  0.002821\n",
       "4        2  0.002653\n",
       "5   import  0.002646\n",
       "6      com  0.002271\n",
       "7      www  0.002240\n",
       "8        1  0.002215\n",
       "9      dog  0.002213\n",
       "10     get  0.002152\n",
       "11  camera  0.002058\n",
       "12    club  0.002050\n",
       "13  messag  0.001981\n",
       "14    text  0.001955\n",
       "15  inform  0.001937\n",
       "16       s  0.001929\n",
       "17    http  0.001882\n",
       "18    flag  0.001862\n",
       "19  servic  0.001846"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_df=pd.DataFrame(sp_result)\n",
    "sp_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u</td>\n",
       "      <td>0.009996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>0.008211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>come</td>\n",
       "      <td>0.007281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>home</td>\n",
       "      <td>0.006678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lor</td>\n",
       "      <td>0.006153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m</td>\n",
       "      <td>0.005814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>will</td>\n",
       "      <td>0.005472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.005206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wat</td>\n",
       "      <td>0.004796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>now</td>\n",
       "      <td>0.004560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time</td>\n",
       "      <td>0.004299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s</td>\n",
       "      <td>0.003942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>get</td>\n",
       "      <td>0.003678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>just</td>\n",
       "      <td>0.003666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>alreadi</td>\n",
       "      <td>0.003571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>can</td>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ok</td>\n",
       "      <td>0.003514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>want</td>\n",
       "      <td>0.003431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>thank</td>\n",
       "      <td>0.003428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0         u  0.009996\n",
       "1        go  0.008211\n",
       "2      come  0.007281\n",
       "3      home  0.006678\n",
       "4         2  0.006516\n",
       "5       lor  0.006153\n",
       "6         m  0.005814\n",
       "7      will  0.005472\n",
       "8         4  0.005206\n",
       "9       wat  0.004796\n",
       "10      now  0.004560\n",
       "11     time  0.004299\n",
       "12        s  0.003942\n",
       "13      get  0.003678\n",
       "14     just  0.003666\n",
       "15  alreadi  0.003571\n",
       "16      can  0.003534\n",
       "17       ok  0.003514\n",
       "18     want  0.003431\n",
       "19    thank  0.003428"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_df=pd.DataFrame(h_result)\n",
    "h_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
